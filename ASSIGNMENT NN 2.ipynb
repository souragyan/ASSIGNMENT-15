{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('gas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>TEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "      <td>114.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "      <td>114.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "      <td>114.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "      <td>114.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "      <td>114.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "      <td>111.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "      <td>111.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "      <td>110.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "      <td>110.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "      <td>111.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     CDP      CO  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  10.605  3.1547   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  10.598  3.2363   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  10.601  3.2012   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  10.606  3.1923   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  10.612  3.2484   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  10.400  4.5186   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  10.433  4.8470   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  10.483  7.9632   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  10.533  6.2494   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  10.583  4.9816   \n",
       "\n",
       "          NOX     TEY  \n",
       "0      82.722  114.70  \n",
       "1      82.776  114.72  \n",
       "2      82.468  114.71  \n",
       "3      82.670  114.72  \n",
       "4      82.311  114.72  \n",
       "...       ...     ...  \n",
       "15034  79.559  111.61  \n",
       "15035  79.917  111.78  \n",
       "15036  90.912  110.19  \n",
       "15037  93.227  110.74  \n",
       "15038  92.498  111.58  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ENERGY']=(df['TEY']>134)*1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENERGY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENERGY\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df[['ENERGY']].copy()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     CDP      CO  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  10.605  3.1547   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  10.598  3.2363   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  10.601  3.2012   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  10.606  3.1923   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  10.612  3.2484   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  10.400  4.5186   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  10.433  4.8470   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  10.483  7.9632   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  10.533  6.2494   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  10.583  4.9816   \n",
       "\n",
       "          NOX  \n",
       "0      82.722  \n",
       "1      82.776  \n",
       "2      82.468  \n",
       "3      82.670  \n",
       "4      82.311  \n",
       "...       ...  \n",
       "15034  79.559  \n",
       "15035  79.917  \n",
       "15036  90.912  \n",
       "15037  93.227  \n",
       "15038  92.498  \n",
       "\n",
       "[15039 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df.iloc[:,0:10]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12031, 10) (12031, 1)\n",
      "(3008, 10) (3008, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasmodel=Sequential()\n",
    "kerasmodel.add(Dense(12,input_dim=10,activation='relu'))\n",
    "kerasmodel.add(Dense(8,activation='relu'))\n",
    "kerasmodel.add(Dense(1,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPILING MODEL\n",
    "kerasmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1204/1204 [==============================] - 17s 10ms/step - loss: 10.5650 - accuracy: 0.6865 9s - loss: 36.5277 - acc - ETA: 8s - loss: 29.4769 - - - ETA: 5s - loss: 16.8696 - accuracy:  - ETA: 5s - lo - ETA: 3s - l - ETA: 1s - loss: 11.9520 - accuracy:  - ETA: 1s - loss:\n",
      "Epoch 2/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.6023 - accuracy: 0.7694\n",
      "Epoch 3/150\n",
      "1204/1204 [==============================] - 13s 11ms/step - loss: 0.5817 - accuracy: 0.7797 - ETA: 1s - loss: 0.5 - ETA: 0s - loss: 0.5\n",
      "Epoch 4/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.5017 - accuracy: 0.78660s -\n",
      "Epoch 5/150\n",
      "1204/1204 [==============================] - 11s 10ms/step - loss: 0.7276 - accuracy: 0.76423s - loss: 0.7960 - accuracy:  - ETA: 3s - loss: 0.7924 - accuracy - ETA: 3s - l - ETA: 2s - loss: 0.7671 - accuracy - ETA: 0s - loss: - ETA: 0s - loss: 0.7299 - accuracy: \n",
      "Epoch 6/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.6426 - accuracy: 0.76516s - loss: 0.7338 -  - ETA: 4s - l - ETA: 1s - - ETA: 0s - loss: 0.6462 \n",
      "Epoch 7/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.4743 - accuracy: 0.7845 1s - los - ETA: 0s - los\n",
      "Epoch 8/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.5246 - accuracy: 0.77320s - loss: 0.5271 - ac - ETA: 0s - loss: 0.5259 - \n",
      "Epoch 9/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.4420 - accuracy: 0.7937\n",
      "Epoch 10/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.4338 - accuracy: 0.79340s\n",
      "Epoch 11/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.4802 - accuracy: 0.7768\n",
      "Epoch 12/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.4191 - accuracy: 0.7930\n",
      "Epoch 13/150\n",
      "1204/1204 [==============================] - 11s 10ms/step - loss: 0.4224 - accuracy: 0.7956\n",
      "Epoch 14/150\n",
      "1204/1204 [==============================] - 13s 11ms/step - loss: 0.5109 - accuracy: 0.7759\n",
      "Epoch 15/150\n",
      "1204/1204 [==============================] - ETA: 0s - loss: 0.4218 - accuracy: 0.8010 ETA: 0s - loss: 0.4219 - accuracy: 0. - 12s 10ms/step - loss: 0.4218 - accuracy: 0.8010\n",
      "Epoch 16/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.4035 - accuracy: 0.79750s -\n",
      "Epoch 17/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3884 - accuracy: 0.79570s - loss: 0.3885 - ac\n",
      "Epoch 18/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.4207 - accuracy: 0.78961s - loss: - ETA: 0s - l\n",
      "Epoch 19/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.4357 - accuracy: 0.7902\n",
      "Epoch 20/150\n",
      "1204/1204 [==============================] - 13s 11ms/step - loss: 0.4144 - accuracy: 0.7899\n",
      "Epoch 21/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3937 - accuracy: 0.79782s\n",
      "Epoch 22/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.4091 - accuracy: 0.79653s - - ETA: 2s - loss: 0.4140 - accuracy:  - ETA: 0s - los\n",
      "Epoch 23/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3775 - accuracy: 0.8057\n",
      "Epoch 24/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.4043 - accuracy: 0.7914\n",
      "Epoch 25/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3727 - accuracy: 0.79990s - loss: 0.3726 - accu\n",
      "Epoch 26/150\n",
      "1204/1204 [==============================] - 11s 10ms/step - loss: 0.4628 - accuracy: 0.7789\n",
      "Epoch 27/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3693 - accuracy: 0.8059\n",
      "Epoch 28/150\n",
      "1204/1204 [==============================] - 11s 10ms/step - loss: 0.3908 - accuracy: 0.7944\n",
      "Epoch 29/150\n",
      "1204/1204 [==============================] - 13s 11ms/step - loss: 0.4180 - accuracy: 0.7975\n",
      "Epoch 30/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3636 - accuracy: 0.8130 3s - - ETA: 0s - loss: 0.3636 - ac\n",
      "Epoch 31/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3669 - accuracy: 0.8103\n",
      "Epoch 32/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3709 - accuracy: 0.8116 0s - loss: 0.371\n",
      "Epoch 33/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3772 - accuracy: 0.8093 0s - loss: 0.3774 - ac\n",
      "Epoch 34/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3681 - accuracy: 0.8124\n",
      "Epoch 35/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3523 - accuracy: 0.8150\n",
      "Epoch 36/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3673 - accuracy: 0.8073\n",
      "Epoch 37/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3605 - accuracy: 0.8146\n",
      "Epoch 38/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3687 - accuracy: 0.8059  - ETA: 1s - loss: 0.3709 - ac - ETA\n",
      "Epoch 39/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3387 - accuracy: 0.8237\n",
      "Epoch 40/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3441 - accuracy: 0.8172\n",
      "Epoch 41/150\n",
      "1204/1204 [==============================] - 11s 10ms/step - loss: 0.3382 - accuracy: 0.8207\n",
      "Epoch 42/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3626 - accuracy: 0.80811s - loss: 0.3643 - accuracy: 0. - ETA: 1s - loss: 0.3642 -  - ETA: 0s - loss: 0 - ETA: 0s - loss: 0.3630 - \n",
      "Epoch 43/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3511 - accuracy: 0.8171\n",
      "Epoch 44/150\n",
      "1204/1204 [==============================] - ETA: 0s - loss: 0.3426 - accuracy: 0.8127 ETA: 9s - loss: 0.3461 - ac - ETA: 5s - loss: 0.3 - - 11s 9ms/step - loss: 0.3426 - accuracy: 0.8127\n",
      "Epoch 45/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3693 - accuracy: 0.8095\n",
      "Epoch 46/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3456 - accuracy: 0.8114 2s - ETA: 2s -\n",
      "Epoch 47/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3483 - accuracy: 0.8156\n",
      "Epoch 48/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3377 - accuracy: 0.81852s - loss: 0.3379 - accuracy:  - ETA: 1s - loss: 0.3379 - accuracy - ETA:  - ETA: 1s - loss: 0.3378 - accuracy: 0. - ETA: 0s - loss: 0.3378 - accuracy: 0.81 - ETA: 0s - loss: 0.3378 - accuracy:  - ETA: 0s - los\n",
      "Epoch 49/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3266 - accuracy: 0.8262 0s - loss: 0.3\n",
      "Epoch 50/150\n",
      "1204/1204 [==============================] - 13s 11ms/step - loss: 0.3205 - accuracy: 0.8349\n",
      "Epoch 51/150\n",
      "1204/1204 [==============================] - 10s 8ms/step - loss: 0.3251 - accuracy: 0.8303 0s - loss: 0.3251 - \n",
      "Epoch 52/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3321 - accuracy: 0.82230s - loss: - ETA: 0s - loss: 0.3322 - accuracy: \n",
      "Epoch 53/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3298 - accuracy: 0.8175 \n",
      "Epoch 54/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3199 - accuracy: 0.8291\n",
      "Epoch 55/150\n",
      "1204/1204 [==============================] - 10s 9ms/step - loss: 0.3334 - accuracy: 0.8233\n",
      "Epoch 56/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3205 - accuracy: 0.8270\n",
      "Epoch 57/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3165 - accuracy: 0.8349\n",
      "Epoch 58/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3169 - accuracy: 0.8300 0s - loss: 0.3\n",
      "Epoch 59/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3311 - accuracy: 0.8231\n",
      "Epoch 60/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3265 - accuracy: 0.8225\n",
      "Epoch 61/150\n",
      "1204/1204 [==============================] - 10s 9ms/step - loss: 0.3227 - accuracy: 0.8261\n",
      "Epoch 62/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3323 - accuracy: 0.8222\n",
      "Epoch 63/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3163 - accuracy: 0.8279\n",
      "Epoch 64/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3214 - accuracy: 0.8337\n",
      "Epoch 65/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3300 - accuracy: 0.82480s - loss: 0.3300 - accuracy\n",
      "Epoch 66/150\n",
      "1204/1204 [==============================] - 13s 11ms/step - loss: 0.3108 - accuracy: 0.8349\n",
      "Epoch 67/150\n",
      "1204/1204 [==============================] - 11s 10ms/step - loss: 0.3132 - accuracy: 0.8342\n",
      "Epoch 68/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.2993 - accuracy: 0.8436\n",
      "Epoch 69/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3101 - accuracy: 0.84000s - loss: 0.310\n",
      "Epoch 70/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3176 - accuracy: 0.8309\n",
      "Epoch 71/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3024 - accuracy: 0.8398\n",
      "Epoch 72/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3095 - accuracy: 0.8335\n",
      "Epoch 73/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3119 - accuracy: 0.83573s - loss: 0.312\n",
      "Epoch 74/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3045 - accuracy: 0.8413: 0s - loss: 0\n",
      "Epoch 75/150\n",
      "1204/1204 [==============================] - 13s 11ms/step - loss: 0.3078 - accuracy: 0.8414 - ETA: 0s - loss: 0.3077 - accu\n",
      "Epoch 76/150\n",
      "1204/1204 [==============================] - 13s 10ms/step - loss: 0.3187 - accuracy: 0.8275\n",
      "Epoch 77/150\n",
      "1204/1204 [==============================] - ETA: 0s - loss: 0.3165 - accuracy: 0.8314 ETA: 0s - loss: 0.3164 - accu - 13s 11ms/step - loss: 0.3165 - accuracy: 0.8314\n",
      "Epoch 78/150\n",
      "1204/1204 [==============================] - 13s 10ms/step - loss: 0.3126 - accuracy: 0.83600s\n",
      "Epoch 79/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3269 - accuracy: 0.82782s - loss: 0.3311 - accu - ETA: 1s - loss: 0.3303 - accuracy:  - ETA:  - ETA: 0s - loss: 0\n",
      "Epoch 80/150\n",
      "1204/1204 [==============================] - 13s 10ms/step - loss: 0.3067 - accuracy: 0.8304\n",
      "Epoch 81/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3140 - accuracy: 0.8294\n",
      "Epoch 82/150\n",
      "1204/1204 [==============================] - 13s 11ms/step - loss: 0.3127 - accuracy: 0.83142s\n",
      "Epoch 83/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3007 - accuracy: 0.8381\n",
      "Epoch 84/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3023 - accuracy: 0.8429\n",
      "Epoch 85/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3032 - accuracy: 0.84081s - loss: - ETA: 0s - loss: 0 - ETA: 0s - loss: 0.3032 - accuracy: 0.84\n",
      "Epoch 86/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3048 - accuracy: 0.83493s - los - ETA: 2s - loss: 0.3056 - accuracy:  - ETA: 2s - loss: 0.3055 - accuracy:  - ETA: 2s - loss: 0.3054 -  - - ETA: 0s - loss: 0.304\n",
      "Epoch 87/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.2974 - accuracy: 0.84280s - loss: 0.2971 - accu\n",
      "Epoch 88/150\n",
      "1204/1204 [==============================] - 13s 11ms/step - loss: 0.3148 - accuracy: 0.8314\n",
      "Epoch 89/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3148 - accuracy: 0.8260 0s - loss: 0.3149 - accuracy: \n",
      "Epoch 90/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.2968 - accuracy: 0.8449\n",
      "Epoch 91/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.2986 - accuracy: 0.8393\n",
      "Epoch 92/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.2991 - accuracy: 0.84096s - ETA: 4s - loss: 0.3033 - accuracy: 0. - ETA: 4s\n",
      "Epoch 93/150\n",
      "1204/1204 [==============================] - 13s 11ms/step - loss: 0.3075 - accuracy: 0.8327\n",
      "Epoch 94/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3004 - accuracy: 0.83915s - loss: 0.2 - ETA: 4s - ETA: 0s -\n",
      "Epoch 95/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3061 - accuracy: 0.8355\n",
      "Epoch 96/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3007 - accuracy: 0.83760s - loss: 0.3009 - \n",
      "Epoch 97/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3107 - accuracy: 0.8359\n",
      "Epoch 98/150\n",
      "1204/1204 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.8392 ETA: 6s - l - ETA: 0s - loss: 0.3042 - accuracy: 0. - ETA: 0s - loss: 0.3042 -  - ETA: 0s - loss: 0.3042 - accuracy: 0. - 11s 9ms/step - loss: 0.3042 - accuracy: 0.8392\n",
      "Epoch 99/150\n",
      "1204/1204 [==============================] - 13s 10ms/step - loss: 0.3184 - accuracy: 0.8305\n",
      "Epoch 100/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3171 - accuracy: 0.8344\n",
      "Epoch 101/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3036 - accuracy: 0.8393 0s - loss: 0.3037 - accu\n",
      "Epoch 102/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3014 - accuracy: 0.8373\n",
      "Epoch 103/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3000 - accuracy: 0.8404 0s - loss: 0.3 - ETA: 0s - loss: 0.3000 - accuracy\n",
      "Epoch 104/150\n",
      "1204/1204 [==============================] - 14s 11ms/step - loss: 0.3031 - accuracy: 0.8358\n",
      "Epoch 105/150\n",
      "1204/1204 [==============================] - 11s 10ms/step - loss: 0.3165 - accuracy: 0.8269\n",
      "Epoch 106/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3061 - accuracy: 0.8339\n",
      "Epoch 107/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3139 - accuracy: 0.8276 2s - loss: 0.3170 - accura - ETA: 2s - loss: 0 - ETA: 1s - loss: 0.3 - ETA: 1s - loss: 0.3150 - accuracy:  - ETA: 0s\n",
      "Epoch 108/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3055 - accuracy: 0.8407\n",
      "Epoch 109/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.2967 - accuracy: 0.8406\n",
      "Epoch 110/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3017 - accuracy: 0.83992s - los\n",
      "Epoch 111/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3066 - accuracy: 0.8344\n",
      "Epoch 112/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.2990 - accuracy: 0.8431\n",
      "Epoch 113/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.2998 - accuracy: 0.8376\n",
      "Epoch 114/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3037 - accuracy: 0.8395 0s - loss: 0.3038 - accuracy\n",
      "Epoch 115/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.2935 - accuracy: 0.8438 0s - loss: 0.2935 - accuracy: 0.\n",
      "Epoch 116/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3053 - accuracy: 0.83390s - loss: 0.3052 - accuracy: 0.\n",
      "Epoch 117/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.2945 - accuracy: 0.8390\n",
      "Epoch 118/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.2986 - accuracy: 0.8316 4s - loss: 0.2 - ETA: 4s - ETA: 0s - loss: 0.2983  - ETA: 0s - loss: 0.2985 - \n",
      "Epoch 119/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3000 - accuracy: 0.8340 0s - loss: 0.3000 \n",
      "Epoch 120/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3030 - accuracy: 0.8316\n",
      "Epoch 121/150\n",
      "1204/1204 [==============================] - ETA: 0s - loss: 0.3017 - accuracy: 0.83 - 11s 9ms/step - loss: 0.3017 - accuracy: 0.8377\n",
      "Epoch 122/150\n",
      "1204/1204 [==============================] - 13s 10ms/step - loss: 0.3016 - accuracy: 0.83171s - ETA: 0s - loss: 0.3011 - ac\n",
      "Epoch 123/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.2988 - accuracy: 0.8494\n",
      "Epoch 124/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.2957 - accuracy: 0.8399 0s - loss: 0.2954 - ac - ETA: 0s - loss: 0.2956 - accu\n",
      "Epoch 125/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.3017 - accuracy: 0.8214\n",
      "Epoch 126/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3052 - accuracy: 0.83411s - loss: 0.3056 - accura - ETA: 0s - loss:\n",
      "Epoch 127/150\n",
      "1204/1204 [==============================] - 11s 9ms/step - loss: 0.2934 - accuracy: 0.8433\n",
      "Epoch 128/150\n",
      "1204/1204 [==============================] - 13s 11ms/step - loss: 0.2991 - accuracy: 0.84170s - loss: 0.2991 - accu\n",
      "Epoch 129/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3178 - accuracy: 0.8209\n",
      "Epoch 130/150\n",
      "1204/1204 [==============================] - 13s 11ms/step - loss: 0.3012 - accuracy: 0.8412\n",
      "Epoch 131/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3047 - accuracy: 0.8266\n",
      "Epoch 132/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.2912 - accuracy: 0.84742s - loss: 0.2887 -  - ETA: 1s - loss: 0.2901 - accuracy:  - ETA:  - ETA: 0s - loss: 0.2911 - accuracy: 0.\n",
      "Epoch 133/150\n",
      "1204/1204 [==============================] - 13s 11ms/step - loss: 0.3004 - accuracy: 0.83981s - loss: 0.3\n",
      "Epoch 134/150\n",
      "1204/1204 [==============================] - 13s 11ms/step - loss: 0.2926 - accuracy: 0.8441\n",
      "Epoch 135/150\n",
      "1204/1204 [==============================] - 13s 11ms/step - loss: 0.3111 - accuracy: 0.8328\n",
      "Epoch 136/150\n",
      "1204/1204 [==============================] - 13s 10ms/step - loss: 0.2932 - accuracy: 0.84461s - loss: 0\n",
      "Epoch 137/150\n",
      "1204/1204 [==============================] - 13s 11ms/step - loss: 0.2901 - accuracy: 0.84871s - loss: 0.2905  - ETA: 1s - loss: 0.2905 - accura - ETA: \n",
      "Epoch 138/150\n",
      "1204/1204 [==============================] - 14s 11ms/step - loss: 0.2895 - accuracy: 0.84914s - loss: 0.291 - ETA: 2s - loss: 0.2899 - accuracy: 0. - ETA - ETA: 0s - loss: 0.2896 - accuracy:  - ETA: 0s - loss: 0\n",
      "Epoch 139/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.2983 - accuracy: 0.8422: 1 - ETA: 6s - loss: 0.2 - ETA: 5s - loss: 0 - ETA: 1s - l - ETA: 0s -\n",
      "Epoch 140/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.2982 - accuracy: 0.83897s - loss: 0.2922 -  - ETA: 6s - loss: 0.2952 - accuracy: 0. - ETA: 5s - loss: 0.2954 - ac - ETA: 5s - ETA: 1s - loss: 0.2981 - accu - ETA: 0s - loss: 0.298\n",
      "Epoch 141/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3006 - accuracy: 0.8381\n",
      "Epoch 142/150\n",
      "1204/1204 [==============================] - 11s 10ms/step - loss: 0.2962 - accuracy: 0.8411\n",
      "Epoch 143/150\n",
      "1204/1204 [==============================] - 14s 11ms/step - loss: 0.2999 - accuracy: 0.8345\n",
      "Epoch 144/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3029 - accuracy: 0.8376\n",
      "Epoch 145/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.2892 - accuracy: 0.8422\n",
      "Epoch 146/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3064 - accuracy: 0.8305\n",
      "Epoch 147/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.3377 - accuracy: 0.80600s - loss: 0.3387 - ac\n",
      "Epoch 148/150\n",
      "1204/1204 [==============================] - 12s 10ms/step - loss: 0.2914 - accuracy: 0.8353\n",
      "Epoch 149/150\n",
      "1204/1204 [==============================] - 14s 11ms/step - loss: 0.2986 - accuracy: 0.8399\n",
      "Epoch 150/150\n",
      "1204/1204 [==============================] - 13s 11ms/step - loss: 0.2924 - accuracy: 0.8418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21ebbaad100>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FITTING MODEL\n",
    "kerasmodel.fit(x_train,y_train,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 4s 8ms/step - loss: 0.2675 - accuracy: 0.8497\n",
      "train accuracy: 84.97\n"
     ]
    }
   ],
   "source": [
    "#TRAIN ACCURACY\n",
    "_,accuracy=kerasmodel.evaluate(x_train,y_train)\n",
    "print('train accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8503989361702128"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred=kerasmodel.predict_classes(x_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
